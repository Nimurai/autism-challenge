{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "<table style=\"width:100%; background-color:transparent;\">\n",
    "  <tr style=\"background-color:transparent;\">\n",
    "    <td style=\"background-color:transparent;\">[<img src=\"http://project.inria.fr/saclaycds/files/2017/02/logoUPSayPlusCDS_990.png\" width=\"70%\">](http://www.datascience-paris-saclay.fr)</td>\n",
    "    <td style=\"background-color:transparent;\">[<img src=\"https://paris-saclay-cds.github.io/autism_challenge/images/institut_pasteur_logo.svg\" width=\"30%\">](https://research.pasteur.fr/en/team/group-roberto-toro/)</td>\n",
    "  </tr>\n",
    "</table> \n",
    "</div>\n",
    "\n",
    "<center><h1>Imaging-psychiatry challenge: predicting autism</h1></center>\n",
    "\n",
    "<center><h3>A data challenge on Autism Spectrum Disorder detection</h3></center>\n",
    "<br/>\n",
    "<center>_Roberto Toro (Institut Pasteur), Nicolas Traut (Institut Pasteur), Anita Beggiato (Institut Pasteur), Katja Heuer (Institut Pasteur),<br /> Gael Varoquaux (Inria, Parietal), Alex Gramfort (Inria, Parietal), Balazs Kegl (LAL),<br /> Guillaume Lemaitre (CDS), Alexandre Boucaud (CDS), and Joris van den Bossche (CDS)_</center>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Set up your conda environment\n",
    "\n",
    "Before going to the nitty-gritty, make sure you installed all required packages as in the ami_environment.yml file.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by downloading the data from Internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem import get_train_data\n",
    "from problem import get_test_data\n",
    "\n",
    "data_train, labels_train = get_train_data()\n",
    "data_test, labels_test = get_test_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Task 1*\n",
    "\n",
    "Print the number of males and females in the training and test sets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from problem import get_cv\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def evaluation(X, y):\n",
    "    pipe = make_pipeline(FeatureExtractor(), Classifier())\n",
    "    cv = get_cv(X, y)\n",
    "    # cv = StratifiedKFold(n_splits=5, random_state=42)\n",
    "    results = cross_validate(pipe, X, y, scoring=['roc_auc', 'accuracy'], cv=cv,\n",
    "                             verbose=1, return_train_score=True,\n",
    "                             n_jobs=2)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def evaluation_predict(X,y):\n",
    "    # Note: in the cross_validate function, they use StratifiedShuffleSplit which allows for resampling\n",
    "    pipe = make_pipeline(FeatureExtractor(), Classifier())\n",
    "    cv = StratifiedKFold(n_splits=5, random_state=42) \n",
    "    \n",
    "    results = cross_val_predict(pipe, X, y, cv=cv,\n",
    "                             verbose=1, n_jobs=2, method='predict')\n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Task 2*\n",
    "Print the proportion of males and females in each fold of the cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5,shuffle=True, random_state=42) \n",
    "data_train_sex = np.array(data_train['participants_sex'])\n",
    "for train_index, test_index in cv.split(data_train,labels_train):\n",
    "    train = data_train_sex[train_index]\n",
    "    test = data_train_sex[test_index]\n",
    "    # TO DO"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load the submission"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each submission defines a `FeatureExtractor` and a `Classifier`. It relies on:\n",
    "\n",
    "* the file `submissions/<submission_name>/feature_extractor.py` corresponding to the feature extractor;\n",
    "* the file `submission/<submission_name>/classifier.py` corresponding to the classifier.\n",
    "\n",
    "In the cells below, you can change the name of the `<submission_name>` to load on the desired solution and later run it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Feature extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load submissions/starting_kit/feature_extractor.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load submissions/starting_kit/classifier.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Run the evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the data from https://zenodo.org/record/3625740/files/basc064.zip ...\n",
      "Decompressing the archive ...\n",
      "Downloading the data from https://zenodo.org/record/3625740/files/basc122.zip ...\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from submissions.pearrr_original.classifier import Classifier\n",
    "from submissions.pearrr_original.feature_extractor import FeatureExtractor\n",
    "\n",
    "# Make sure you download the functional data, if it is not already stored on your drive\n",
    "from download_data import fetch_fmri_time_series\n",
    "fetch_fmri_time_series(atlas='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structural MRI features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluation(data_train, labels_train)\n",
    "\n",
    "print(\"Training score ROC-AUC: {:.3f} +- {:.3f}\".format(\n",
    "    np.mean(results['train_roc_auc']), np.std(results['train_roc_auc'])))\n",
    "print(\"Validation score ROC-AUC: {:.3f} +- {:.3f} \\n\".format(\n",
    "    np.mean(results['test_roc_auc']), np.std(results['test_roc_auc'])))\n",
    "\n",
    "print(\"Training score accuracy: {:.3f} +- {:.3f}\".format(\n",
    "    np.mean(results['train_accuracy']), np.std(results['train_accuracy'])))\n",
    "print(\"Validation score accuracy: {:.3f} +- {:.3f}\".format(\n",
    "    np.mean(results['test_accuracy']), np.std(results['test_accuracy'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = evaluation_predict(data_train,labels_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Task 3*\n",
    "\n",
    "Complete this function to return model's accuracy for male and female samples seperately for each fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_protectedGroups(predictions, cv_split, data):\n",
    "  fold_pred = [predictions[test] for train, test in cv.split(data_train,labels_train)]\n",
    "  fold_labels = [np.array(labels_train)[test] for train, test in cv.split(data_train,labels_train)]\n",
    "\n",
    "  data_train_sex = np.array(data_train['participants_sex'])\n",
    "  i=0\n",
    "  for train_index, test_index in cv_split:\n",
    "\n",
    "      # TODO\n",
    "      i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, random_state=42) \n",
    "cv_split = cv.split(data_train, labels_train)\n",
    "\n",
    "accuracy_protectedGroups(predictions, cv_split, data_train)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "autism-challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "2eedc0f8ca948ae606d9322b9d8c29697e867f7e99cdda1733c50a729984d87e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
